% ************************** Thesis Abstract *****************************
% Use `abstract' as an option in the document class to print only the titlepage and the abstract.
\begin{abstract}
Reasoning over knowledge expressed in natural language is a problem at the forefront of artificial intelligence. Open domain question answering is one of the core tasks of this problem, and concerned with enabling machines the capability of reasoning unknown answers. Relational learning has been explored as a framework for this task, where knowledge graphs (KGs) are used to encode facts about a domain using entities and relations. The Resource Description Framework formalism, subject-predictate-object, is then used to encode these facts into a knowledge base (KB). Encoding all possible facts may be intractable and presents a significant challenge to this approach. Link prediction over KBs has shown promise in solving this problem, where possible facts are identified by scoring unknown relationships between entities. \newline
\noindent This thesis explores latent feature modelling using tensor factorisation as an approach to link prediction. Tensor decompositions are an attractive approach as relational domains are usually high-dimensional and sparse, a setting where factorisation methods have shown very good results. Previous approaches have focused on shallow models that can scale to large datasets, and recently deep models have been applied, neural tensor factorisation, as these models are more expressive, and automatically learn the most useful latent features for entities and relations. In this work, we introduce training algorithm optimisations to the Neural Tensor Network (NTN) and HypER neural tensor factorisation models. \newline
\noindent  We make use of the TensorFlow reimplimentation of NTNs, and apply early stopping, adaptive moment estimation and random search hyperparamter optimisation. We see improvements in both cost and accuracy over the baseline reimplementation using standard link prediction benchmark datasets,  Wordnet and Freebase. We then apply optimisations to the HypER model training algorithm, beginning with compensating for covariate shift caused by hypernetworks by using introducing normalisation, HypER+. We see similar performance to the baseline using the WN18 dataset, and see significant improvement using the FB15k dataset. We then extend our optimisation by initialising entities and relations using GloVe pre-trained word vectors. We see marginal improvements over the baseline using the WN18RR and FB15k-237 datasets. Despite only marginal improvements, our results establish HypER+ as the state-of-the-art model in link prediction using latent feature modelling. 
\end{abstract}
 