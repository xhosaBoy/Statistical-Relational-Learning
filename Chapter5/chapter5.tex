%!TEX root = ../thesis.tex
%*******************************************************************************
%*********************************** Fifth Chapter *****************************
%*******************************************************************************

\chapter{Conclusions}  %Title of the First Chapter

\ifpdf
    \graphicspath{{Chapter5/Figs/Raster/}{Chapter5/Figs/PDF/}{Chapter5/Figs/}}
\else
    \graphicspath{{Chapter5/Figs/Vector/}{Chapter5/Figs/}}
\fi


%********************************** %First Section  **************************************

Statistical relational learning (SRL) is a relatively young field artificial intelligence (AI). The field is concerned with reasoning about knowledge expressed as a graph, and tries to solve the core task of open domain question answering. A number of exciting applications can be realised should this problem be addressed, including an evolution of search engines, scientific recommender systems and conversational AI. Link prediction is the preferred SRL technique used for this core task, and most recently has been delivered using latent feature modelling. \newline
Deep learning methods have lead to the development of a number of successful latent feature modelling approaches for link prediction. Performance on traditional benchmark metrics now stands at 95\% and 79\% on WN18 and FB15k respectively. This has been achieved whilst striving to ensure algorithms remain scalable, with the intent of tractability. Performance on more modern datasets has not been as prolific, and state-of-the-art (SOTA) currently stands at 43\% and 25\% on WN18RR and FB15k-237 respectively. This suggests a lot of work remains in latent feature modellling, or alternative avenues of reasoning should be explored. \newline
Some progress in link prediction was recently achieved by (Nathani et al. 2019) using a graph modelling approach ~\citep{nathani2019learning}. They were able to achieve an accuracy performance of 46\% on FB15k-237. This represents an increase of 19\%, a staggering improvement. They were not able to replicate the results for WN18RR however, and achieved a performance of 36\%, 7\% below the latent feature modelling based result. (Pinter and Eisenstein 2018) ~\citep{pinter-eisenstein-2018-predicting} were able to achieve at SOTA performance on WN18RR of 45\%, an increase of 2\% on the latent feature model based approach. Graph modelling approaches clearly demonstrate potential in push link prediction performance forward and, unlike latent feature modelling, have yet to be substantially researched. They represent a potential alternative avenue of reasoning. \newpage

That being said, recent advances in latent feature modelling were achieved using new neural compositional model, specifically neural tensor factorisation. These models replaced the dot product between subject and predicate representations with a convolutional operator. It stands to reason that doing the same for compositional operator between the generated latent representation and object representation, could produce link prediction performance gains not yet achieved. This simple adjustment would produce an end-to-end neural compositional model which would extend entity-relational interaction expressiveness even further and increase model capacity. In pursuit of improved link prediction performance, in this dissertation we argued 1) machine learning methods are a sensible approach to reasoning about knowledge expressed in natural language. Latent feature modelling in SRL extends logical inference techniques, an early attempt at this problem, by allowing the relaxation of plausibility constraints - expressing facts using a measure of uncertainty, and retaining plausible facts, whilst discarding implausible facts. We argued that 2) Deep learning models can be used to improve latent feature modelling approaches to link prediction in SRL and 3) semantic information in pre-trained word vectors can be used used to model richer entity-relational interactions. \newline
