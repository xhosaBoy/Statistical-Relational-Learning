%!TEX root = ../thesis.tex
%*******************************************************************************
%*********************************** Fourth Chapter *****************************
%*******************************************************************************


\chapter{Results and analysis}  %Title of the Fourth Chapter

\ifpdf
     \graphicspath{{Figs/Chapter4/}}
\else
    \graphicspath{{Chapter4/Figs/Vector/}{Chapter4/Figs/}}
\fi

This chapter discusses three hypotheses examined in the dissertation: the application of modern deep learning techniques to the training algorithm of recursive neural tensor networks, compensating for covariate shift introduced by a hypernetwork for convolutional tensor factorisation, and finally the intialisation of entity and relation embeddings using pre-trained word vectors. 


%********************************** %Recursive Neural Tensor Networks  **************************************

\section{Recursive neural tensor networks}

\noindent \textbf{Model summary.} This model is inspired by recursive neural networks (RCN). RCNs are combined with the bilinear tensor product to produce a latent entity-relational representation. This representation is pass through a neural network to generate a relational score between two entities (NTN). 

\noindent \textbf{Contrastive max-margin loss.} The contrastive max-margin loss is used to train the NTN model. The input consists of an subject-predicate pair. A non-related object is then presented as a corrupt entity. A relational score is then computed for the target triple, as well as the corrupt triple, and the difference between the two is then contrasted. The task is for the model is then to produce a higher relational score for the true triple than the false triple. If the model gets it wrong, a loss is generated and back propagated through the network to update model parameters. \par

\noindent \textbf{Experimental setup.} We use the following link prediction benchmark datasets: Wordnet - a lexical database for English, it is a taxonomy with hypernyms (is-a) relationships, and synonym sets. Freebase - a large collaborative knowledge base consisting of data about the world composed mainly by its community members. It was an online collection of structured data harvested from many sources, including user-submitted wiki contributions. \newline
Visualisations of the respective knowledge graphs are presented below:

\begin{figure}[H]
   	\centering
    	\includegraphics[width=\textwidth]{Wordnet}
	\caption{Wordnet Entities and Relations Graphplot}
\end{figure}

\begin{figure}[H]
   	\centering
    	\includegraphics[width=\textwidth]{Freebase}
	\caption{Freebase Entity and Relations Graphplot}
\end{figure}

\noindent We used the Tensorflow framework to develop our model.  This model is built on top of the Neural Tensor model introduced by (Socher and Chen, et al. 2013) \unskip ~\citep{socher2013reasoning} and implemented in TensorFlow by (Doss, LeNail and Liu 2015) \unskip ~\citep{Doss2015}. Pre-trained word vectors are used to initialise entity and relational embeddings during model training. These embeddings are dynamically adjusted during the training process to generate latent representations specific to the knowledge domain. Property counts for the respective knowledge graphs are presented below:

\bigskip

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\centering
    		\includegraphics[width=0.45\textwidth]{Wordnet_Counts}
		\caption{Wordnet Property Barplot}
		}
	\hfill
	\parbox{.5\linewidth}{
   		\centering
    		\includegraphics[width=0.45\textwidth]{Freebase_Counts}
		\caption{Freebase Property Barplot}
		}
\end{figure}

\begin{table}[H]
	\parbox{.5\linewidth}{
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Property} & \textbf{Count}  \\
  			\hline
  			Entities & 38,696  \\
  			Relations & 11  \\
  			Triples & 136,611  \\
			&
		\end{tabular}
		\caption{Wordnet Property Counts}
		}
	\hfill
	\parbox{.5\linewidth}{
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Property} & \textbf{Count}  \\
  			\hline
  			Entities & 75,043   \\
  			Relations & 13  \\
  			Triples & 375,499  \\
			&
		\end{tabular}
		\caption{Freebase Property Counts}
		}
\end{table}


\noindent Summary statistics of the respective knowledge graphs Resource Description Framework (RDF) decomposition - subject, predicate, object - are presented below:

%********************************** %Predicate  **************************************

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{Wordnet_Predicate_Counts}
		\caption{Wordnet Predicate Barplot}
		}
	\hfill
	\parbox{.5\linewidth}{
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{Freebase_Predicate_Counts}
		\caption{Freebase Predicate Barplot}
		}
\end{figure}

\begin{table}[H]
	\parbox{.5\linewidth}{
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Statistic} & \textbf{Value}  \\
  			\hline
			Count & 11 \\
			Max & 43,312  \\
			Min & 1,229  \\
  			Median & 7,705  \\
  			IQR & 7,257.5  \\
				&
		\end{tabular}
		\caption{Wordnet Predicate Statistics}
		}
	\hfill
	\parbox{.5\linewidth}{
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Statistic} & \textbf{Value}  \\
  			\hline
			Count & 13 \\
			Max & 73,897  \\
			Min & 4, 464  \\
  			Median & 21,149  \\
  			IQR & 34,033  \\
				&
		\end{tabular} 
		\caption{Freebase Predicate Statistics}
		}
\end{table}

%********************************** %Subject **************************************

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{Wordnet_Subject_Counts}
		\caption{Wordnet Subject Barplot}
		}
	\hfill
	\parbox{.5\linewidth}{
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{Freebase_Subject_Counts}
		\caption{Freebase Subject Barplot}
		}
\end{figure}

\begin{table}[H]
	\parbox{.5\linewidth}{
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Statistic} & \textbf{Value}  \\
  			\hline
			Count & 32,720 \\
			Max & 619 \\
			Min & 1 \\
  			Median & 2 \\
  			IQR & 2 \\
				&
		\end{tabular}
		\caption{Wordnet Subject Statistics}
		}
	\hfill
	\parbox{.5\linewidth}{
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Statistic} & \textbf{Value}  \\
  			\hline
			Count & 67,393 \\
			Max & 37 \\
			Min & 1 \\
  			Median & 5 \\
  			IQR & 4 \\
				&
		\end{tabular}
		\caption{Freebase Subject Statistics}
		}
\end{table}

%********************************** %Object  **************************************

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{Wordnet_Object_Counts}
		\caption{Wordnet Object Barplot}
		}
	\hfill
	\parbox{.5\linewidth}{
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{Freebase_Object_Counts}
		\caption{Freebase Object Barplot}
		}
\end{figure}


\begin{table}[H]
	\parbox{.5\linewidth}{
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Statistic} & \textbf{Value}  \\
  			\hline
			Count & 33,011 \\
			Max & 537 \\
			Min & 1 \\
  			Median & 3 \\
  			IQR & 2 \\
				&
		\end{tabular}
		\caption{Wordnet Object Statistics}
		}
	\hfill
	\parbox{.5\linewidth}{
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Statistic} & \textbf{Value}  \\
  			\hline
			Count & 15,342 \\
			Max & 59,663 \\
			Min & 1 \\
  			Median & 3 \\
  			IQR & 6 \\
				&
		\end{tabular}
		\caption{Freebase Object Statistics}
		}
\end{table}

\noindent For Wordnet, it can be seen that relations are skewed toward "has instance" 43,312 occurrences, and "type of" 36,659 occurrences. We would expect poor performance from the model for out-of-sample data containing relations that are not "has instance" or "type of". Freebase relations are somewhat more uniform, however four relations have occurrences under 10,000. We would expect reasonable performance across all relations for this dataset. \par

\noindent Wordnet and Freebae subjects are somewhat uniform, although the median number of occurrences is 2 and 5 respectively, with an IQR of 2 and 4 respectively. This are thus sparse distributions of data points, and the model will need to rely on  similarity of subject features in order to produce sensible inference. Wordnet object occurrences are somewhat uniform. Freebase object occurrences are skewed, with a single object, "male" occurring 59,663 times, representing 15,88\% of facts. This is in comparison to a median object occurrence of 3 and an interquartile range of 6. We would expect poor performance from a Freebase link prediction model given this distribution of objects. 


%********************************** %Modern Deep Learning Techniques **************************************

\section{NTN with Modern Deep Learning Techniques}

\noindent We change the training algorithm optimiser from AdaGrad to Adam, and implement model hyperparameter optimisation using random grid search. The the model was trained on a MacBook Pro 2015 with 8 cores, 16GB RAM, and 512GB SSD. We evaluate the model by ranking the accuracy scores of the predicted triples for the respective datasets. \bigskip

\noindent \textbf{Code to reproduce} \newline
Updated NTN:  \url{https://github.com/xhosaBoy/deep-knowledge-modelling} \newline
Baseline: \url{https://github.com/xhosaBoy/recursive-neural-tensor-networks}

\subsubsection{Link Prediction Results}
The link prediction accuracy results of the RNTN model, a neural factorisation model compared against linear factorisation models, are presented in table 5.1:

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{Wordnet_Cost_Results_Early_Stopping}
		\caption{Wordnet Cost}
		}
	\hfill
	\parbox{.5\linewidth}{
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{Freebase_Cost_Results}
		\caption{Freebase Cost}
		}
\end{figure}

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{Wordnet_Accuracy_Results_Early_Stopping}
		\caption{Wordnet Accuracy}
		}
	\hfill
	\parbox{.5\linewidth}{
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{Freebase_Accuracy_Results}
		\caption{Freebase Accuracy}
		}
\end{figure}

\begin{table}[H]
	\centering
	\begin{tabular}{lllllllllll}
  		\textbf{Model} & \textbf{Wordnet} & \textbf{Freebbase} & \textbf{Avg} \\
  		\hline
  		Distance Model & .683 & .610 & .647 \\
  		Hadamard Model & .800 & .688 & .744 \\
  		Single Layer Model & .760 & .853 & .807 \\
  		Bilinear Model & \textbf{.841} & \textbf{.877} & \textbf{.859} \\
  		NTN & .562 & .535 & .549 \\
  		\hline
  		Updated NTN & .674 & .548 & .611 \\
	\end{tabular}
	\caption{Link prediction accuracy on Wordnet and Freebase}
\end{table}


%********************************** %HypER and Covariate Shift  **************************************

\section{HypER and Covariate Shift}

\subsubsection{Model Summary} 
HypER is a model that uses convolutional relational filters that are convolved with a subject, producing an intermediate entity-relational representation. This representation is then flattened and pass through a nonlinearity before the dot product taken with an object. This computation generates a relational score between the two entities, which is then passed through a logistic sigmoid to compute a probability of relational plausibility. \newpage

\subsubsection{Binary Cross Entropy Loss}
The binary cross entropy loss is used to train HypER. Like the NTN model, the input consists of an subject-predicate pair, and an object is presented as a target to complete the triple. A relational score is generated for each sample and passed through through a logistic sigmoid. Loss is generated by comparing the produced likelihood with the expected likelihood, 0 or 1. The sum of all losses is aggregated and back propagated through the network for parameter update. 

\subsubsection{Experimental Setup} 

We use the following link prediction benchmark datasets: WN18 (Bordes et al. 2013) is a subset of Wordnet, a database containing lexical relations between words. The knowledge graph contains 40,943 entities and 18 relations. FB15k - (Bordes et al. 2013) is a subset of Freebase, a large database of facts about the real world. FB15k contains 14,951 entities and 1,345 relations. \bigskip

Visualisations of the respective knowledge graphs are presented below:

\begin{figure}[H]
  	\caption{WN18 Entities and Relations Graphplot}
   	\centering
    	\includegraphics[width=\textwidth]{WN18_Graph}
\end{figure}

\begin{figure}[H]
  	\caption{FB15k Entity and Relations Graphplot}
   	\centering
    	\includegraphics[width=\textwidth]{FB15k_Graph}
\end{figure}

We used the Pytorch framework to develop our model. This model is built on top of the HypER model introduced by (Balaˇzevi´c, Allen, and Hospedales 2018) ~\citep{balazevic2019hypernetwork}.  Randomly initialised entity and relational embeddings are used to initialise model training. These embeddings are dynamically adjusted during the training process to generate latent representations specific to the knowledge domain. Property counts for the respective knowledge graphs are presented below:

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18 Property Barplot}
   		\centering
    		\includegraphics[width=0.45\textwidth]{WN18_Counts}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k Property Barplot}
   		\centering
    		\includegraphics[width=0.45\textwidth]{FB15k_Counts}
		}
\end{figure}

\begin{table}[H]
	\parbox{.5\linewidth}{
		\caption{WN18 Property Counts}
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Property} & \textbf{Count}  \\
  			\hline
  			Entities & 40,943  \\
  			Relations & 18  \\
  			Triples & 151,442 \\
		\end{tabular}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k Property Counts}
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Property} & \textbf{Count}  \\
  			\hline
  			Entities & 14,951   \\
  			Relations & 1,345  \\
  			Triples & 592,213  \\
		\end{tabular}
		}
\end{table}

Summary statistics of the respective knowledge graphs Resource Description Framework (RDF) decomposition - subject, predicate, object - are presented below:

%********************************** %Predicate  **************************************

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18 Predicate Barplot}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18_Predicate_Counts}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k Predicate Barplot}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k_Predicate_Counts}
		}
\end{figure}

\begin{table}[H]
	\parbox{.5\linewidth}{
		\caption{WN18 Predicate Statistics}
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Statistic} & \textbf{Value}  \\
  			\hline
			Count & 18 \\
			Max & 37,221  \\
			Min & 86 \\
  			Median & 3,242.5  \\
  			IQR & 6,190.75  \\
		\end{tabular}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k Predicate Statistics}
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Statistic} & \textbf{Value}  \\
  			\hline
			Count & 1,345 \\
			Max & 19,764  \\
			Min & 1  \\
  			Median & 26  \\
  			IQR & 166  \\
		\end{tabular}
		}
\end{table}

%********************************** %Subject **************************************

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18 Subject Barplot}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18_Subject_Counts}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k Subject Barplot}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k_Subject_Counts}
		}
\end{figure}


\begin{table}[H]
	\parbox{.5\linewidth}{
		\caption{WN18 Subject Statistics}
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Statistic} & \textbf{Value}  \\
  			\hline
			Count & 32,544 \\
			Max & 520 \\
			Min & 1 \\
  			Median & 3 \\
  			IQR & 2 \\
		\end{tabular}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k Subject Statistics}
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Statistic} & \textbf{Value}  \\
  			\hline
			Count &14,865 \\
			Max & 4,381 \\
			Min & 1 \\
  			Median & 27 \\
  			IQR & 32 \\
		\end{tabular}
		}
\end{table}

%********************************** %Object  **************************************

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18 Object Barplot}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18_Object_Counts}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k Object Barplot}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k_Object_Counts}
		}
\end{figure}


\begin{table}[H]
	\parbox{.5\linewidth}{
		\caption{WN18 Object Statistics}
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Statistic} & \textbf{Value}  \\
  			\hline
			Count & 32,543 \\
			Max & 520 \\
			Min & 1 \\
  			Median & 3 \\
  			IQR & 2 \\
		\end{tabular}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k Object Statistics}
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Statistic} & \textbf{Value}  \\
  			\hline
			Count & 14,930 \\
			Max & 9,645 \\
			Min & 1 \\
  			Median & 23 \\
  			IQR & 30 \\
		\end{tabular}
		}
\end{table}

For WN18, it can be seen that relations are skewed toward the relations "hyponym",  "hypernym", and "derivationally related from", with a maximum of 37,221 occurrences. \newline
FB15k relations are somewhat more uniform. We would expect reasonable performance across all relations for this knowledge graph. WN18 and FB15k subjects are somewhat uniform aside from a small number of high occurrences entities, with the median number of occurrences is 3 and 27 respectively, and with an IQR of 2 and 32 respectively. WN18 object occurrences are somewhat uniform. FB15k object occurrences are skewed, with the "United States" partaking in the highest number of facts. This is in comparison to a median object occurrence of 3 and an interquartile range of 23.

%********************************** %HypER+  **************************************

\subsubsection{HypER+}
The hypernetwork module of the HypER model introduces covariate shift. We compensate for this covariate shift by introducing batch normalisation between the hypernetwork and convolutional modules of the architecture, and introduce HypER+. \newline
The the model was trained on Google Cloud Platform, on a N1 series instance with  8 CPU cores, 30GB RAM, 512GB SSD and a Nvidia Tesla P100 GPU. We evaluate the model using standard link prediction benchmarks. \bigskip

\textbf{Code to reproduce} \newline
HypER+: \url{https://github.com/xhosaBoy/HypER-Regularised-Relations} \newline
Baseline: \url{https://github.com/xhosaBoy/HypER-baseline}

\subsubsection{Link Prediction Results}
The link prediction benchmark results of the HypER+ model, compared against other link prediction models, are presented below:

%********************************** %Cost  **************************************

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18 Cost}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18_Cost_Results}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k Cost}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k_Cost_Results}
		}
\end{figure}

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18 Cost Clipped View}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18_Cost_Results_Clipped}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k Cost Clipped View}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k_Cost_Results_Clipped}
		}
\end{figure}

%********************************** %Hits@10  **************************************

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18 Hits@10}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18_hits_at_10_Results}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k Hits@10}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k_hits_at_10_Results}
		}
\end{figure}

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18 Hits@10 Clipped View}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18_hits_at_10_Results_Clipped}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k Hits@10  Clipped View}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k_hits_at_10_Results_Clipped}
		}
\end{figure}

%********************************** %Hits@3  **************************************

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18 Hits@3}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18_hits_at_3_Results}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k Hits@3}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k_hits_at_3_Results}
		}
\end{figure}

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18 Hits@3 Clipped View}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18_hits_at_3_Results_Clipped}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k Hits@3  Clipped View}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k_hits_at_3_Results_Clipped}
		}
\end{figure}

%********************************** %Hits@1  **************************************

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18 Hits@1}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18_hits_at_1_Results}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k Hits@1}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k_hits_at_1_Results}
		}
\end{figure}

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18 Hits@1 Clipped View}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18_hits_at_1_Results_Clipped}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k Hits@1  Clipped View}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k_hits_at_1_Results_Clipped}
		}
\end{figure}

%********************************** %Mean rank **************************************

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18 Mean Rank}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18_mean_rank_Results}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k Mean Rank}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k_mean_rank_Results}
		}
\end{figure}

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18 Mean Rank Clipped View}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18_mean_rank_Results_Clipped}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k Mean Rank Clipped View}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k_mean_rank_Results_Clipped}
		}
\end{figure}

%********************************** %Mean reciprocal rank **************************************

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18 Mean Reciprocal Rank}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18_mean_reciprocal_rank_Results}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k Mean Reciprocal Rank}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k_mean_reciprocal_rank_Results}
		}
\end{figure}

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18 Mean Reciprocal Rank Clipped View}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18_mean_reciprocal_rank_Results_Clipped}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k Mean Reciprocal Rank Clipped View}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k_mean_reciprocal_rank_Results_Clipped}
		}
\end{figure}

%********************************** %Test results **************************************

\begin{table}[H]
	\parbox{.5\linewidth}{
		\caption{Link prediction results on WN18}
		\centering
		\resizebox{0.5\columnwidth}{!}{%
		\begin{tabular}{lllllllllll}
  			\textbf{Model} & \textbf{H@10} & \textbf{H@3} & \textbf{H@1} & \textbf{MR} & \textbf{MRR} \\
  			\hline
  			TransE (Bordes et al. 2013) & .892 & - & - & \textbf{251} & - \\
  			DistMult (Yang et al. 2015) & .936 & .914 & .728 & 902 & .822 \\
  			ComplEx (Trouillon et al. 2016) & .947 & .936 & .936 & - & .941 \\
  			ANALOGY (Liu, Wu, and Yang 2017) & .947 & .944 & .939 & - & .942 \\
  			Neural LP (Yang, Yang, and Cohen 2017) & .945 & - & - & - & .940 \\
			R-GCN (Schlichtkrull et al. 2018) & \textbf{.964} & .929 & .697 & - & .819 \\
			TorusE (Ebisu and Ichise 2018) & .954 & .950 & .943 & - & .947 \\
			ConvE (Dettmers et al. 2018) & .956 & .946 & .935 & 374 & .943 \\
			HypER (Bala\v{z}evi\'c et al. 2019) & .958 & \textbf{.955} & \text{.947} & 431 & \textbf{.951} \\
  			\hline
  			HypER+ (ours) & .957 & .953 & .945 & 599 & .949 \\
		\end{tabular}%
		}}
	\hfill
	\parbox{.5\linewidth}{
	\caption{Link prediction results on FB15k}
		\centering
		\resizebox{0.5\columnwidth}{!}{%
		\begin{tabular}{lllllllllll}
  			\textbf{Model} & \textbf{H@10} & \textbf{H@3} & \textbf{H@1} & \textbf{MR} & \textbf{MRR} \\
  			\hline
  			TransE (Bordes et al. 2013) & .471 & - & - & 125 & - \\
  			DistMult (Yang et al. 2015) & .824 & .733 & .546 & 97 & .654 \\
  			ComplEx (Trouillon et al. 2016) & .840 & .759 & .599 & - & .692 \\
  			ANALOGY (Liu, Wu, and Yang 2017) & .854 & .785 & .646 & - & .725 \\
  			Neural LP (Yang, Yang, and Cohen 2017) & .837 & - & - & - & .760 \\
			R-GCN (Schlichtkrull et al. 2018) & .842 & .760 & .601 & - & .696 \\
			TorusE (Ebisu and Ichise 2018) & .832 & .771 & .674 & - & .733\\
			ConvE (Dettmers et al. 2018) & .831 & .723 & .558 & 51 & .657 \\
			HypER (Bala\v{z}evi\'c et al. 2019) & .885 & .829 & .734 & \textbf{44} & .790 \\
  			\hline
  			HypER+ (ours) & \textbf{.894} & \textbf{.856} & \textbf{.790} & 79 & \textbf{.829} \\
		\end{tabular}%
		}}
\end{table}


%********************************** %HypER+ with Pre-Trained Word Embeddings  **************************************

\section{HypER+ with Pre-Trained Word Vectors}

\subsubsection{Model Summary} 
We extend HypER+ to make use of pre-trained GloVe word vectors. This model replaces Xavier initailised entity and relation embeddings with aggregated GloVe embeddings. \newline
HypER+ is also trained using the binary cross entropy loss.

\subsubsection{Experimental Setup} 

We use the following benchmark datasets: WN18RR is a subset of WN18, created by Dettmers et al. by removing the inverse relations from WN18. WN18RR contains 40,943 entities and 11 relations. FB15k-237 - was created by Toutanova et al., noting that the validation and test sets of FB15k and WN18 contain the inverse of many relations present in the training set, making it easy for simple models to do well. FB15k-237 is a subset of FB15k with the inverse relations removed. It contains 14,541 entities and 237 relations. \newpage

Visualisations of the respective knowledge graphs are presented below:

\begin{figure}[H]
  	\caption{WN18RR Entities and Relations Graphplot}
   	\centering
    	\includegraphics[width=\textwidth]{WN18RR_Graph}
\end{figure}

\begin{figure}[H]
  	\caption{FB15k-237 Entity and Relations Graphplot}
   	\centering
    	\includegraphics[width=\textwidth]{FB15k-237_Graph}
\end{figure} \newpage

We used the Pytorch framework to develop our model. This model is built on top of the HypER+ model introduced by (Magangane, Luyolo, and Brink, Wille 2019).  Glove pre-trained word vectors are used to initialise entity and relational embeddings for model training. These embeddings are dynamically adjusted during the training process to generate latent representations specific to the knowledge domain. \bigskip

Property counts for the respective knowledge graphs are presented below:

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18RR Property Barplot}
   		\centering
    		\includegraphics[width=0.45\textwidth]{WN18RR_Counts}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k-237 Property Barplot}
   		\centering
    		\includegraphics[width=0.45\textwidth]{FB15k-237_Counts}
		}
\end{figure}

\begin{table}[H]
	\parbox{.5\linewidth}{
		\caption{WN18RR Property Counts}
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Property} & \textbf{Count}  \\
  			\hline
  			Entities & 40,943  \\
  			Relations & 11  \\
  			Triples & 93,003 \\
		\end{tabular}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k-237 Property Counts}
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Property} & \textbf{Count}  \\
  			\hline
  			Entities & 14,541   \\
  			Relations & 237  \\
  			Triples & 310,116  \\
		\end{tabular}
		}
\end{table}

Summary statistics of the respective knowledge graphs Resource Description Framework (RDF) decomposition - subject, predicate, object - are presented below:

%********************************** %Predicate **************************************

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18RR Predicate Barplot}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18RR_Predicate_Counts}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k-237 Predicate Barplot}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k-237_Predicate_Counts}
		}
\end{figure}

\begin{table}[H]
	\parbox{.5\linewidth}{
		\caption{WN18RR Predicate Statistics}
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Statistic} & \textbf{Value}  \\
  			\hline
			Count & 11 \\
			Max & 37,221  \\
			Min & 86 \\
  			Median & 3150  \\
  			IQR & 5433.5  \\
		\end{tabular}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k-237 Predicate Statistics}
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Statistic} & \textbf{Value}  \\
  			\hline
			Count & 237 \\
			Max & 16,391 \\
			Min & 45  \\
  			Median & 426  \\
  			IQR & 819 \\
		\end{tabular}
		}
\end{table}

%********************************** %Subject **************************************

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18RR Subject Barplot}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18RR_Subject_Counts}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k-237 Subject Barplot}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k-237_Subject_Counts}
		}
\end{figure}


\begin{table}[H]
	\parbox{.5\linewidth}{
		\caption{WN18RR Subject Statistics}
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Statistic} & \textbf{Value}  \\
  			\hline
			Count & 32,349 \\
			Max & 494 \\
			Min & 1 \\
  			Median & 2 \\
  			IQR & 2 \\
		\end{tabular}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k-237 Subject Statistics}
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Statistic} & \textbf{Value}  \\
  			\hline
			Count &13,891 \\
			Max & 1,518 \\
			Min & 1 \\
  			Median & 16 \\
  			IQR & 20 \\
		\end{tabular}
		}
\end{table}

%********************************** %Object **************************************

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18RR Object Barplot}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18RR_Object_Counts}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k-237 Object Barplot}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k-237_Object_Counts}
		}
\end{figure}


\begin{table}[H]
	\parbox{.5\linewidth}{
		\caption{WN18RR Object Statistics}
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Statistic} & \textbf{Value}  \\
  			\hline
			Count & 26,162 \\
			Max & 514 \\
			Min & 1 \\
  			Median & 1 \\
  			IQR & 2 \\
		\end{tabular}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k-237 Object Statistics}
		\centering
		\begin{tabular}{lllllllllll}
  			\textbf{Statistic} & \textbf{Value}  \\
  			\hline
			Count & 13,504 \\
			Max & 7,124 \\
			Min & 1 \\
  			Median & 10 \\
  			IQR & 16 \\
		\end{tabular}
		}
\end{table}

For WN18RR, it can be seen that relations are skewed toward the relations "hypernym" and "derivationally related from", with a maximum of 37,221 occurrences, with an IQR of 5433.5 and 819 respectively. FB15k-237 are skewed toward film relations. We would expect reasonable performance across this type of relation for the knowledge graph. \newline
WN18R and FB15k-237 subjects are somewhat uniform aside from a small number of high occurrences entities, with the median number of occurrences is 3 and 16 respectively, and with an IQR of 2 and 20 respectively. 
WN18RR object occurrences are somewhat uniform. FB15k-237 object occurrences are skewed, with the "United States" partaking in the highest number of facts. This is in comparison to a median object occurrence of 1 and an interquartile range of 10,
and an IQR of 2 and 16 respectively. Such high variance in FB15k-237 suggests poor potential model performance for FB15k-237 relative to WN18RR.  

%********************************** %Pre-Trained Word Embeddings **************************************

\subsubsection{HypER+ with Glove Word Embeddings}

HypER+ here is implemented using Glove pre-trained word embeddings. \newline
The the model was trained on Google Cloud Platform, on a N1 series instance with  8 CPU cores, 30GB RAM, 512GB SSD and a Nvidia Tesla P100 GPU. We evaluate the model using standard link prediction benchmarks. \newline 

\textbf{Code to reproduce} \newline
HypER+ with GloVe: \url{https://github.com/xhosaBoy/HypER-Pretrained-Word-Vectors} \newline
Baseline: \url{https://github.com/xhosaBoy/HypER-baseline} \newpage

\subsubsection{Link Prediction Results}
The link prediction benchmark results of the HypER+ with pre-trained embeddings model, compared against other link prediction models, are presented below:

%********************************** %Cost **************************************

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18RR Cost}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18RR_Cost_Results}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k-237 Cost}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k-237_Cost_Results}
		}
\end{figure}

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18RR Cost Clipped View}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18RR_Cost_Results_Clipped}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k-237 Cost Clipped View}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k-237_Cost_Results_Clipped}
		}
\end{figure}

%********************************** %Hits@10 **************************************

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18RR Hits@10}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18RR_hits_at_10_Results}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k-237 Hits@10}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k-237_hits_at_10_Results}
		}
\end{figure}

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18RR Hits@10 Clipped View}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18RR_hits_at_10_Results_Clipped}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k-237 Hits@10  Clipped View}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k-237_hits_at_10_Results_Clipped}
		}
\end{figure}

%********************************** %Hits@3 **************************************

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18RR Hits@3}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18RR_hits_at_3_Results}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k-237 Hits@3}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k-237_hits_at_3_Results}
		}
\end{figure}

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18RR Hits@3 Clipped View}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18RR_hits_at_3_Results_Clipped}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k-237 Hits@3  Clipped View}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k-237_hits_at_3_Results_Clipped}
		}
\end{figure}

%********************************** %Hits@1 **************************************

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18RR Hits@1}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18RR_hits_at_1_Results}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k-237 Hits@1}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k-237_hits_at_1_Results}
		}
\end{figure}

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18RR Hits@1 Clipped View}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18RR_hits_at_1_Results_Clipped}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k-237 Hits@1  Clipped View}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k-237_hits_at_1_Results_Clipped}
		}
\end{figure}

%********************************** %Mean rank **************************************

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18RR Mean Rank}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18RR_mean_rank_Results}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k-237 Mean Rank}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k-237_mean_rank_Results}
		}
\end{figure}

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18RR Mean Rank Clipped View}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18RR_mean_rank_Results_Clipped}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k-237 Mean Rank Clipped View}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k-237_mean_rank_Results_Clipped}
		}
\end{figure}

%********************************** %Mean reciprocal rank **************************************

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18RR Mean Reciprocal Rank}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18RR_mean_reciprocal_rank_Results}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k-237 Mean Reciprocal Rank}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k-237_mean_reciprocal_rank_Results}
		}
\end{figure}

\begin{figure}[H]
	\parbox{.5\linewidth}{
   		\caption{WN18RR Mean Reciprocal Rank Clipped View}
   		\centering
    		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{WN18RR_mean_reciprocal_rank_Results_Clipped}
		}
	\hfill
	\parbox{.5\linewidth}{
		\caption{FB15k-237 Mean Reciprocal Rank Clipped View}
   		\centering
		\includegraphics[width=0.45\textwidth, height=0.2\textheight]{FB15k-237_mean_reciprocal_rank_Results_Clipped}
		}
\end{figure}

%********************************** %Test results **************************************

\begin{table}[H]
	\parbox{.5\linewidth}{
		\caption{Link prediction results on WN18RR}
		\centering
		\resizebox{0.5\columnwidth}{!}{%
		\begin{tabular}{lllllllllll}
  			\textbf{Model} & \textbf{H@10} & \textbf{H@3} & \textbf{H@1} & \textbf{MR} & \textbf{MRR} \\
  			\hline
  			DistMult (Yang et al. 2015) & .490 & .440 & .390 & 5110 & .430 \\
  			ComplEx (Trouillon et al. 2016) & .510 & .460 & .410 & 5261 & .440 \\
  			Neural LP (Yang, Yang, and Cohen 2017) & - & - & - & - & - \\
			MINERVA (Das et al. 2018) & - & - & - & - & - \\
			ConvE (Dettmers et al. 2018) & .520 & .440 & .400 & 4187 & .430 \\
			HypER (Bala\v{z}evi\'c et al. 2019) & .522 & .477 & \textbf{.436} & 5798 & .465 \\
  			\hline
  			HypER+ (ours) & \textbf{.552} & \textbf{.481} & .432 & \textbf{1586} & \textbf{.471} \\
		\end{tabular}%
		}}
	\hfill
	\parbox{.5\linewidth}{
	\caption{Link prediction results on FB15k-237}
		\centering
		\resizebox{0.5\columnwidth}{!}{%
		\begin{tabular}{lllllllllll}
  			\textbf{Model} & \textbf{H@10} & \textbf{H@3} & \textbf{H@1} & \textbf{MR} & \textbf{MRR} \\
  			\hline
  			DistMult (Yang et al. 2015) & .419 & .263 & .155 & 254 & .241 \\
  			ComplEx (Trouillon et al. 2016) & .428 & .275 & .158 & 339 & .247 \\
  			Neural LP (Yang, Yang, and Cohen 2017) & .408 & - & - & - & .250 \\
			MINERVA (Das et al. 2018) & .456 & - & - & - & - \\
			ConvE (Dettmers et al. 2018) & .501 & .356 & .237 & 244 & .325 \\
			HypER (Bala\v{z}evi\'c et al. 2019) & .520 & \textbf{.376} & \textbf{.252} & 250 & \textbf{.341} \\
  			\hline
  			HypER+ (ours) & \textbf{.522} & \textbf{.376} & \textbf{.252} & \textbf{215} & \textbf{.341} \\
		\end{tabular}%
		}}
\end{table}

%********************************** %Chapter Summary  **************************************

\section{Summary}

In this chapter we've discussed: \newline
\textbf{NTN with Modern Deep Learning Techniques.} We've attempted a simple improvement in the NTN model by appplying modern deep learning training techniques, including Adam and hyperparameter random search. The results indicate there potential performance gains by deep models simply by updating their respective training algorithms with modern methods. In this instance, we see an accuracy gain of 6.2\%, for the Wordnet and Freebase datasets. \newline
\textbf{HypER+.}  Here we compensate for the covariate shift introduced by the hypernetwork in convolutional factorisation. The distributional drift is pronounced enough that we are able to improve the Hit@1 accuracy on of the original HypER model on average by 2.7\%, for the WN18 and FB15k datasets.\newline
\textbf{HypER+. with GloVe} Finally we extend HypER+ to make use of pre-trained GloVe word vectors. The semantic information inherent in these embeddings somewhat overpower the structural information present in the knowledge graph. The resultant model on average decreases the Hit@1 accuracy on of the original HypER model on average by 0.4\%, for the WN18RR and FB15k-237 datasets. \newline
